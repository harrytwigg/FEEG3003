\chapter{An Investigation in Using DDSP to Learn and Synthesize Vocal Features}

The adaptation of DDSP to synthesize vocal features such as singing using the additional MFFC layer was chosen for further investigation.

All research was undertaken using Google Colab notebooks and cloud hardware, primarily NVIDIA Tesla V100 GPUs.

Two separate models were trained, one for a male voice (Chris Martin from Coldplay) and one for a female voice (Taylor Swift). This was done to see how the DDSP architecture would handle different vocies e.g. Alto or Tennor differently.

It was hypothesized that 2 albums would be the optimal size for any training dataset. Premilinary investigations on smaller datasets yielded significant overfitting and poor performance when any of the F0, amplitude latent features were modified during inference. Datasets of any greater size would be preferred. However, larger models would be slower to train.

\begin{figure}[!ht]
    \centering
    \caption{Songs and albums going into each training dataset}
\end{figure}

\input{research/dataset_preparation/dataset_preparation.tex}

\input{research/training/training.tex}

\input{research/results/results.tex}