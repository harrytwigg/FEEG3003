\chapter{Introduction}
\label{ch:introduction}

Using computerised methods to synthesise music programmatically has historically been a complex problem. Music contains thousands of sound features every second in the time domain that are difficult to teach accurately to a neural network.

Many potential applications would be opened up if a deep learning model could be devised to accurately learn, understand, and synthesise the fundamental features of music. These uses include many potentially artistic and business applications:

\begin{itemize}
    \item Rapidly synthesising new vocal tracks for music production.
    \item Pitch transposing a piece of music, e.g. transposing a piece of music down an octave or up an octave.
    \item Changing room acoustics, e.g. if a piece of music was played in any echoic room, the model could be used to re-synthesise the same piece of music in an anechoic environment.
    \item Change the singing voice in a particular piece of music, similarly to deep fakes.
    \item Musical remixes of existing songs with different singers.
    \item Potentially brand new forms of artistic expression, with a neural network perhaps able to produce vocal features that are impossible to create naturally.
\end{itemize}

In recent years, deep learning methods have been applied to this problem, attempting to synthesise musical instrumentals and vocals. However, success to date has proven varied. Moreover, even if a network successfully learns how to interpret musical features, the output of models often sounds fake or jarring to the listener due to inaccurate pitch and timbre representations and a lack of temporal context.

Regardless, synthesising vocals has proven less successful than synthesising instrumentals; this is primarily due to the complexity of the human voice. The human voice consists of many different vocal modes and features that are difficult for a neural network to learn.

This thesis first explores various approaches to synthesising music using machine learning-based methods. Then, the merits and limitations of the approaches are evaluated regarding synthesising vocals and as a justification for the selection of DDSP. DDSP is a novel approach to synthesising music using deep learning.

DDSP is investigated with the ultimate goal of synthesising human singing with adjustable latent space parameters (F0 and loudness) and demonstrating its potential to be a viable solution to synthesising music.

\input{introduction/aims_and_objectives.tex}

\input{introduction/methodology.tex}