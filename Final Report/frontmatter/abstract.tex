\begin{center}
  \textsc{Abstract}
\end{center}

\noindent

In this report, a deep learning architecture called DDSP is used for synthesizing realistic vocal features. DDSP is a collection of machine learning models, differentiable versions of standard digital signal processing elements such as oscillators, noise filters, and other valuable tools for learning how to decode, learn and subsequently synthesize new musical audio signals.

The DDSP architecture is applied to a set of vocal samples of two different artist's voices, to create a model for each respectively. The models extract pitch, amplitude, and timbre information from the vocal samples. Several inferencing tests are then conducted to determine the performances of the trained models at various tasks.

Finally, the results are concluded, and areas for improvement for future work are suggested.