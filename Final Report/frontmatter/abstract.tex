\begin{center}
  \textsc{Abstract}
\end{center}

\noindent

In this report, various deep learning architectures are compared to determine the best for synthesizing realistic vocal features. The one with the most significant potential (DDSP) is investigated further. DDSP is a collection of machine learning models, differentiable versions of standard digital signal processing elements such as oscillators, noise filters, and other valuable tools for learning how to decode, learn and subsequently synthesize new musical audio signals.

The DDSP model is applied to a set of vocal samples of a single artist's voice, with the model extracting pitch, amplitude, and timbre information from the vocal samples. The model is then trained to recreate the vocal samples from the extracted information. Several inferencing tests are then conducted to determine the performances of the trained models at various tasks.

Finally, the results are concluded, and areas for improvement for future work are suggested.