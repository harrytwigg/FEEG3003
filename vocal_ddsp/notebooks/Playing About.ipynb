{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"xny8O97QaCeQ"},"outputs":[],"source":["import sys\n","from pathlib import Path\n","import os\n","from google.colab import drive\n","\n","drive.mount('/content/drive', force_remount=True)\n","\n","# Check for project path\n","PROJECT_PATH = Path('/content/drive/My Drive/vocal_ddsp')\n","if not PROJECT_PATH.exists():\n","    raise Exception(f'Project path {PROJECT_PATH} does not exist')\n","  \n","# Check if separated data exists\n","TRAINING_DATASET_PATH = f\"{str(PROJECT_PATH)}/training_data\"\n","if not Path(TRAINING_DATASET_PATH).exists():\n","    raise Exception(f\"Training dataset path not found at '{TRAINING_DATASET_PATH}'\") \n","\n","# Check for checkpoints path\n","CHECKPOINTS_PATH = f\"{str(PROJECT_PATH)}/checkpoints\"\n","if not Path(CHECKPOINTS_PATH).exists():\n","  os.mkdir(CHECKPOINTS_PATH)\n","  assert Path(CHECKPOINTS_PATH).exists()\n","\n","# Check for gins path\n","GINS_PATH = f\"{str(PROJECT_PATH)}/gins\"\n","if not Path(GINS_PATH).exists():\n","    raise Exception(f\"Gins path not found at '{GINS_PATH}'\") \n","\n","# Import DDSP to collab\n","%tensorflow_version 2.x\n","%pip install -qU ddsp\n","%pip install apache-beam\n","%pip install python-snappy\n","\n","import warnings\n","import copy\n","import os\n","import time\n","import glob\n","import gin\n","import librosa\n","import pickle\n","import crepe\n","import ddsp\n","import ddsp.training\n","\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import tensorflow.compat.v2 as tf\n","import tensorflow_datasets as tfds\n","import ipywidgets as widgets\n","\n","from ddsp.colab import colab_utils\n","from ddsp.training import postprocessing\n","from google.colab import files\n","from ipywidgets import interact\n","from IPython.display import Javascript\n","\n","%config InlineBackend.figure_format='retina'\n","\n","gpu_info = !nvidia-smi\n","gpu_info = '\\n'.join(gpu_info)\n","if gpu_info.find('failed') >= 0:\n","  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n","  print('and then re-execute this cell.')\n","else:\n","  print(gpu_info)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oQzFo6Geb0MB"},"outputs":[],"source":["import random\n","\n","\n","class TrainedModel:\n","  \"\"\"Loads a trained model from its original dataset and provides a series of\n","  helper functions to evaluate and process its data\"\"\"\n","\n","  def __init__(self, dataset_relative_path, model_relative_path = None):\n","    if model_relative_path is None:\n","      model_relative_path = dataset_relative_path\n","\n","    # Check for dataset path existance\n","    dataset_path = f\"{TRAINING_DATASET_PATH}/{dataset_relative_path}\"\n","    if not Path(dataset_path).exists():\n","      raise Exception(f\"Failed to load model instance, dataset_relative_path {self.dataset_path} does not exist\")\n","    \n","    self.dataset_pattern = f\"{dataset_path}/*\"\n","\n","    # Check for model path existance\n","    self.model_path = f\"{CHECKPOINTS_PATH}/{model_relative_path}\"\n","    if not Path(self.model_path).exists():\n","      raise Exception(f\"Failed to load model instance, model_relative_path {self.model_path} does not exist\")\n","\n","    self.data_provider = ddsp.training.data.TFRecordProvider(self.dataset_pattern)\n","    \n","    # Gin config file\n","    self.gin_file = os.path.join(self.model_path, 'operative_config-0.gin')\n","    with gin.unlock_config():\n","      gin.parse_config_file(self.gin_file, skip_unknown=True)\n","    \n","    # See if any stats were saved\n","    dataset_stats_file = os.path.join(self.model_path, 'dataset_statistics.pkl')\n","\n","    try:\n","      if tf.io.gfile.exists(dataset_stats_file):\n","        with tf.io.gfile.GFile(dataset_stats_file, 'rb') as f:\n","          self.DATASET_STATS = pickle.load(f)\n","      else:\n","          print('WARNING: pickle file not present')\n","          self.DATASET_STATS = None\n","    except Exception as err:\n","      # Don't throw Exception here\n","      print('Loading dataset statistics from pickle failed: {}.'.format(err))\n","      self.DATASET_STATS = None\n","    \n","    # Load the model\n","    self.model = ddsp.training.models.Autoencoder()\n","    self.model.restore(self.model_path)\n","  \n","  @property\n","  def dataset_length(self):\n","    return len(list(self.get_training_dataset()))\n","  \n","  def get_training_dataset(self, shuffle=False):\n","    return self.data_provider.get_dataset(shuffle=shuffle)\n","  \n","  def generate_audio_from_batch(self, batch):\n","    \"\"\"Infers audio based off of a batch\"\"\"\n","    outputs = self.model(batch, training=False)\n","    return self.model.get_audio_from_outputs(outputs)\n","  \n","  def get_frame(self, shuffle_batching=False):\n","    batch = self.data_provider.get_batch(batch_size=1, shuffle=shuffle_batching)\n","    # Get a 4 second frame someway though the randomised dataset\n","    target_length = int(random.randint(0, self.dataset_length) / 2)\n","    for i, frame in enumerate(iter(batch)):\n","      if i == target_length:\n","        return frame\n","    \n","  \n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GaO2K9vKcdxC"},"outputs":[],"source":["trained_model = TrainedModel(\"TaylorSwiftSelected\", \"TaylorSwiftSelected_h100_n60\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qqDGoOE40UQw"},"outputs":[],"source":["#postprocessing.compute_dataset_statistics(trained_model.data_provider)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CzyHkqgO75Dp"},"outputs":[],"source":["# Compare original and syhnthesized features\n","frame = trained_model.get_frame(shuffle_batching=True)\n","# Generate audio\n","audio = trained_model.generate_audio_from_batch(frame)\n","ddsp.colab.colab_utils.specplot(frame['audio'])\n","ddsp.colab.colab_utils.play(frame['audio'])\n","\n","ddsp.colab.colab_utils.specplot(audio)\n","ddsp.colab.colab_utils.play(audio)\n","#audio_features = ddsp.training.metrics.compute_audio_features(audio)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"X4BjAreyAeg-"},"outputs":[],"source":["from tensorflow.python.ops.numpy_ops import np_config\n","np_config.enable_numpy_behavior()\n","\n","#@title Record or Upload Audio\n","#@markdown * Either record audio from microphone or upload audio from file (.mp3 or .wav) \n","#@markdown * Audio should be monophonic (single instrument / voice)\n","#@markdown * Extracts fundmanetal frequency (f0) and loudness features. \n","\n","record_or_upload = \"Upload (.mp3 or .wav)\"  #@param [\"Record\", \"Upload (.mp3 or .wav)\"]\n","\n","record_seconds =     5#@param {type:\"number\", min:1, max:10, step:1}\n","\n","if record_or_upload == \"Record\":\n","  audio = ddsp.colab.colab_utils.record(seconds=record_seconds)\n","else:\n","  # Load audio sample here (.mp3 or .wav3 file)\n","  # Just use the first file.\n","  #filenames, audios = ddsp.colab.colab_utils.upload()\n","  #audio = audios[0]\n","  audio = frame['audio']\n","if len(audio.shape) == 1:\n","  audio = audio[np.newaxis, :]\n","print('\\nExtracting audio features...')\n","\n","# Plot.\n","ddsp.colab.colab_utils.specplot(audio)\n","ddsp.colab.colab_utils.play(audio)\n","\n","# Setup the session.\n","ddsp.spectral_ops.reset_crepe()\n","\n","# Compute features.\n","start_time = time.time()\n","audio_features = ddsp.training.metrics.compute_audio_features(audio)\n","audio_features['loudness_db'] = audio_features['loudness_db'].astype(np.float32)\n","audio_features_mod = None\n","print('Audio features took %.1f seconds' % (time.time() - start_time))\n","\n","\n","TRIM = -15\n","# Plot Features.\n","fig, ax = plt.subplots(nrows=3, \n","                       ncols=1, \n","                       sharex=True,\n","                       figsize=(6, 8))\n","ax[0].plot(audio_features['loudness_db'][:TRIM])\n","ax[0].set_ylabel('loudness_db')\n","\n","ax[1].plot(librosa.hz_to_midi(audio_features['f0_hz'][:TRIM]))\n","ax[1].set_ylabel('f0 [midi]')\n","\n","ax[2].plot(audio_features['f0_confidence'][:TRIM])\n","ax[2].set_ylabel('f0 confidence')\n","_ = ax[2].set_xlabel('Time step [frame]')\n","\n","print((list(type(k) for k in audio_features.values())))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"idU4Ibgwlgma"},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JPntiVcu-l1W"},"outputs":[],"source":["from ddsp.colab.colab_utils import auto_tune, get_tuning_factor\n","from ddsp.training.postprocessing import detect_notes, fit_quantile_transform\n","DATASET_STATS = trained_model.DATASET_STATS\n","#@title Modify conditioning\n","\n","#@markdown These models were not explicitly trained to perform timbre transfer, so they may sound unnatural if the incoming loudness and frequencies are very different then the training data (which will always be somewhat true). \n","\n","\n","#@markdown ## Note Detection\n","\n","#@markdown You can leave this at 1.0 for most cases\n","threshold = 1 #@param {type:\"slider\", min: 0.0, max:2.0, step:0.01}\n","\n","\n","#@markdown ## Automatic\n","\n","ADJUST = True #@param{type:\"boolean\"}\n","\n","#@markdown Quiet parts without notes detected (dB)\n","quiet = 60 #@param {type:\"slider\", min: 0, max:60, step:1}\n","\n","#@markdown Force pitch to nearest note (amount)\n","autotune = 0 #@param {type:\"slider\", min: 0.0, max:1.0, step:0.1}\n","\n","#@markdown ## Manual\n","\n","\n","#@markdown Shift the pitch (octaves)\n","pitch_shift =  -0.1 #@param {type:\"slider\", min:-2, max:2, step:0.1}\n","\n","#@markdown Adjust the overall loudness (dB)\n","loudness_shift = -200 #@param {type:\"slider\", min:-200, max:20, step:1}\n","\n","\n","audio_features_mod = {k: tf.convert_to_tensor(v) for k, v in audio_features.items()}\n","\n","## Helper functions.\n","def shift_ld(audio_features, ld_shift=0.0):\n","  \"\"\"Shift loudness by a number of ocatves.\"\"\"\n","  audio_features['loudness_db'] += ld_shift\n","  return audio_features\n","\n","\n","def shift_f0(audio_features, pitch_shift=0.0):\n","  \"\"\"Shift f0 by a number of ocatves.\"\"\"\n","  audio_features['f0_hz'] *= 2.0 ** (pitch_shift)\n","  audio_features['f0_hz'] = np.clip(audio_features['f0_hz'], \n","                                    0.0, \n","                                    librosa.midi_to_hz(110.0))\n","  return audio_features\n","\n","\n","mask_on = None\n","\n","if ADJUST and DATASET_STATS is not None:\n","  # Detect sections that are \"on\".\n","  mask_on, note_on_value = detect_notes(audio_features['loudness_db'],\n","                                        audio_features['f0_confidence'],\n","                                        threshold)\n","\n","  if np.any(mask_on):\n","    # Shift the pitch register.\n","    target_mean_pitch = DATASET_STATS['mean_pitch']\n","    pitch = ddsp.core.hz_to_midi(audio_features['f0_hz'])\n","    mean_pitch = np.mean(pitch[mask_on])\n","    p_diff = target_mean_pitch - mean_pitch\n","    p_diff_octave = p_diff / 12.0\n","    round_fn = np.floor if p_diff_octave > 1.5 else np.ceil\n","    p_diff_octave = round_fn(p_diff_octave)\n","    audio_features_mod = shift_f0(audio_features_mod, p_diff_octave)\n","\n","\n","    # Quantile shift the note_on parts.\n","    _, loudness_norm = fit_quantile_transform(\n","        audio_features['loudness_db'],\n","        mask_on,\n","        inv_quantile=DATASET_STATS['quantile_transform'])\n","\n","    # Turn down the note_off parts.\n","    mask_off = np.logical_not(mask_on)\n","    loudness_norm[mask_off] -=  quiet * (1.0 - note_on_value[mask_off][:, np.newaxis])\n","    loudness_norm = np.reshape(loudness_norm, audio_features['loudness_db'].shape)\n","    \n","    audio_features_mod['loudness_db'] = loudness_norm \n","\n","    # Auto-tune.\n","    if autotune:\n","      f0_midi = np.array(ddsp.core.hz_to_midi(audio_features_mod['f0_hz']))\n","      tuning_factor = get_tuning_factor(f0_midi, audio_features_mod['f0_confidence'], mask_on)\n","      f0_midi_at = auto_tune(f0_midi, tuning_factor, mask_on, amount=autotune)\n","      audio_features_mod['f0_hz'] = ddsp.core.midi_to_hz(f0_midi_at)\n","\n","  else:\n","    print('\\nSkipping auto-adjust (no notes detected or ADJUST box empty).')\n","\n","else:\n","  print('\\nSkipping auto-adujst (box not checked or no dataset statistics found).')\n","\n","# Manual Shifts.\n","audio_features_mod = shift_ld(audio_features_mod, loudness_shift)\n","audio_features_mod = shift_f0(audio_features_mod, pitch_shift)\n","\n","\n","\n","# Plot Features.\n","has_mask = int(mask_on is not None)\n","n_plots = 3 if has_mask else 2 \n","fig, axes = plt.subplots(nrows=n_plots, \n","                      ncols=1, \n","                      sharex=True,\n","                      figsize=(2*n_plots, 8))\n","\n","if has_mask:\n","  ax = axes[0]\n","  ax.plot(np.ones_like(mask_on[:TRIM]) * threshold, 'k:')\n","  ax.plot(note_on_value[:TRIM])\n","  ax.plot(mask_on[:TRIM])\n","  ax.set_ylabel('Note-on Mask')\n","  ax.set_xlabel('Time step [frame]')\n","  ax.legend(['Threshold', 'Likelihood','Mask'])\n","\n","ax = axes[0 + has_mask]\n","ax.plot(audio_features['loudness_db'][:TRIM])\n","ax.plot(audio_features_mod['loudness_db'][:TRIM])\n","ax.set_ylabel('loudness_db')\n","ax.legend(['Original','Adjusted'])\n","\n","ax = axes[1 + has_mask]\n","ax.plot(audio_features['f0_hz'][:TRIM])\n","ax.plot(audio_features_mod['f0_hz'][:TRIM])\n","ax.set_ylabel('f0 hz')\n","_ = ax.legend(['Original','Adjusted'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"g2SEx6tyBzOi"},"outputs":[],"source":["#@title #Resynthesize Audio\n","\n","af = audio_features if audio_features_mod is None else audio_features_mod\n","\n","# Run a batch of predictions.\n","start_time = time.time()\n","outputs = trained_model.model(af, training=False)\n","audio_gen = trained_model.model.get_audio_from_outputs(outputs)\n","print('Prediction took %.1f seconds' % (time.time() - start_time))\n","\n","# Plot\n","print('Original')\n","ddsp.colab.colab_utils.play(audio)\n","\n","print('Resynthesis')\n","ddsp.colab.colab_utils.play(audio_gen)\n","\n","ddsp.colab.colab_utils.specplot(audio)\n","plt.title(\"Original\")\n","\n","ddsp.colab.colab_utils.specplot(audio_gen)\n","_ = plt.title(\"Resynthesis\")"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"Playing About.ipynb","provenance":[],"authorship_tag":"ABX9TyOqQ8BTMMdR/fsowC9SqT+I"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}